<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->





<title>Bin Wang(ç‹æ–Œ) - Homepage</title>







<meta property="og:locale" content="en">
<meta property="og:site_name" content="Bin Wang(ç‹æ–Œ)">
<meta property="og:title" content="Bin Wang(ç‹æ–Œ)">


  <link rel="canonical" href="https://github.com/pages/wangbinDL/wangbinDL.github.io/">
  <meta property="og:url" content="https://github.com/pages/wangbinDL/wangbinDL.github.io/">



  <meta property="og:description" content="Research Scientist">









<!-- end SEO -->


<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="assets/css/main.css">

<meta http-equiv="cleartype" content="on">
<head>
  <base target="_blank">
</head>
    <link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
<link rel="manifest" href="images/site.webmanifest">

<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg masthead__menu-home-item"><a href="#about-me">Homepage</a></li>
          
            <li class="masthead__menu-item"><a href="/#about-me">About Me</a></li>
          
            <li class="masthead__menu-item"><a href="/#-news">News</a></li>
          
            <li class="masthead__menu-item"><a href="/#-publications">Publications</a></li>
          
            <li class="masthead__menu-item"><a href="/#-honors-and-awards">Honors and Awards</a></li>
          
            <li class="masthead__menu-item"><a href="/#-education">Education</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div id="main" role="main">
      
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person" class="profile_box">

  <div class="author__avatar">
    <img src="images/wangbin.jpg" class="author__avatar" alt="Bin Wang(ç‹æ–Œ)">
  </div>

  <div class="author__content">
    <h3 class="author__name">Bin Wang(ç‹æ–Œ)</h3>
    <p class="author__bio">Shanghai AI Laboratory</p>
  </div>

  <div class="author__urls-wrapper">
    <!-- <button class="btn btn--inverse">More Info & Contact</button> -->
    <ul class="author__urls social-icons">
      
        <li><div style="white-space: normal; margin-bottom: 1em;">Research Scientist</div></li>
      
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Shanghai, China</li>
      
      
      
      
        <li><a href="mailto:ictwangbin@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://github.com/wangbinDL"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=WljXYoYAAAAJ&hl=en"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
      
      
      
    </ul>
      <div class="author__urls_sm">
      
      
        <a href="mailto:ictwangbin@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i></a>
      
      
       
      
      
      
      
      
      
      
      
      
      
        <a href="https://github.com/wangbinDL"><i class="fab fa-fw fa-github" aria-hidden="true"></i></a>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <a href="https://scholar.google.com/citations?user=WljXYoYAAAAJ&hl=en"><i class="fas fa-fw fa-graduation-cap"></i></a>
      
      
      
      
      
    </div>
  </div>
</div>

  
  </div>

    
      <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
        <meta itemprop="headline" content="">
        <div class="page__inner-wrap">
          <section class="page__content" itemprop="text">
            
<p><span class="anchor" id="about-me"></span></p>

<!-- # Short Bio  -->
<h1 id="biography">Biography</h1>

<p>I am currently a Research Scientist at <a href="https://www.shlab.org.cn/">Shanghai AI Lab</a> and an Adjunct Ph.D. Supervisor at the School of AI, Shanghai Jiao Tong University. My research interests focus on <strong>Multimodal Large Language Models</strong>, <strong>Next-Generation Document Understanding</strong>, and <strong>Data-Centric AI</strong>.</p>

<p>I believe that true innovation stems from deep diving, and more importantly, from the relentless refinement and bold reshaping of existing technologies. <strong>Refusing to settle for the status quo</strong>, my goal is to deliver research that is not only scientifically rigorous but also practically transformativeâ€”tackling the â€œhard problemsâ€ others cannot, to provide unique solutions for the industryâ€™s most critical challenges.</p>

<p>Guided by this philosophy, I lead the R&amp;D of <strong><a href="https://github.com/opendatalab/MinerU">MinerU</a></strong>, an open-source toolkit for high-quality document parsing. The project has garnered over <strong>50k GitHub stars</strong> in just 1.5 years, frequently topping GitHub Trending charts. It is widely adopted by both academia and industry, serving as a <strong>mainstream solution</strong> for enterprises and developers building high-quality <strong>LLM and RAG corpora</strong>. Additionally, I have published over 40 papers in top-tier conferences such as CVPR, ICCV, NeurIPS, and ICLR, with over 4,000 Google Scholar citations.</p>

<hr />

<p>æˆ‘æ˜¯ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤ï¼ˆShanghai AI Labï¼‰çš„é’å¹´ç§‘å­¦å®¶ï¼Œä¸Šæµ·äº¤é€šå¤§å­¦äººå·¥æ™ºèƒ½å­¦é™¢å…¼èŒåšå£«ç”Ÿå¯¼å¸ˆï¼Œå…¥é€‰ä¸Šæµ·å¸‚ä¸œæ–¹è‹±æ‰æ‹”å°–äººæ‰é¡¹ç›®ã€‚æˆ‘çš„ç ”ç©¶èšç„¦äº<strong>å¤šæ¨¡æ€å¤§æ¨¡å‹</strong>ã€<strong>ä¸‹ä¸€ä»£æ™ºèƒ½æ–‡æ¡£ç†è§£</strong>ä»¥åŠ<strong>ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½ï¼ˆData-Centric AIï¼‰</strong>ã€‚</p>

<p>æˆ‘ç›¸ä¿¡çœŸæ­£çš„åˆ›æ–°æºäºæ·±è€•ï¼Œæ›´æºäºå¯¹ç°æœ‰æŠ€æœ¯çš„æè‡´æ‰“ç£¨ä¸å‹‡æ•¢é‡å¡‘ã€‚æˆ‘ä¸å›¿äºæ—¢æœ‰çš„æŠ€æœ¯è¾¹ç•Œï¼Œè€Œæ˜¯è‡´åŠ›äºäº§å‡ºæ—¢å…·å¤‡ç§‘å­¦ä¸¥è°¨æ€§ï¼Œåˆå…·æœ‰å˜é©æ„ä¹‰çš„ç ”ç©¶â€”â€”é€šè¿‡æ”»å…‹é‚£äº›åˆ«äººåšä¸åˆ°çš„éš¾é¢˜ï¼Œä¸ºè¡Œä¸šæœ€å…³é”®çš„æŒ‘æˆ˜æä¾›ç‹¬ä¸€æ— äºŒçš„è§£å†³æ–¹æ¡ˆã€‚ç§‰æŒè¿™ä¸€ç†å¿µï¼Œæˆ‘ä¸»å¯¼ç ”å‘äº†å¼€æºæ–‡æ¡£è§£æå·¥å…· <strong><a href="https://github.com/opendatalab/MinerU">MinerU</a></strong>ã€‚è¯¥é¡¹ç›®åœ¨ä¸€å¹´åŠå†…æ–©è· <strong>50k+ GitHub Stars</strong>ï¼Œå¤šæ¬¡ç™»é¡¶ GitHub Trending å…¨çƒæ¦œå•ï¼Œä¸ä»…åœ¨å­¦æœ¯ç•Œå¹¿å—å¥½è¯„ï¼Œæ›´è¢«äº§ä¸šç•Œå¹¿æ³›é‡‡ç”¨ï¼Œæˆä¸ºä¼—å¤šä¼ä¸šä¸å¼€å‘è€…æ„å»ºé«˜è´¨é‡å¤§æ¨¡å‹è¯­æ–™åŠ RAG è¯­æ–™åº“çš„ä¸»æµé€‰æ‹©ã€‚åŒæ—¶ï¼Œæˆ‘åœ¨ CVPR, ICCV, NeurIPS, ICLR ç­‰é¡¶çº§ä¼šè®®å‘è¡¨è®ºæ–‡ 40 ä½™ç¯‡ï¼Œè°·æ­Œå­¦æœ¯å¼•ç”¨è¶… 4000 æ¬¡ã€‚</p>

<p>æˆ‘ä»¬æŒç»­å¯»æ‰¾ä¼˜ç§€çš„åšå£«ç”Ÿï¼ˆä¸Šäº¤ç­‰é¡¶å°–é«˜æ ¡åšå£«è”åŸ¹åé¢ï¼‰ã€åšå£«åç ”ç©¶å‘˜ã€å®ä¹ ç”ŸåŠå…¨èŒç ”ç©¶äººå‘˜ï¼Œå¦‚æœä½ å¯¹äººå·¥æ™ºèƒ½æ–¹å‘å……æ»¡çƒ­æƒ…ï¼Œè‡ªé©±åŠ›å¼ºï¼Œæ¬¢è¿ç”µå­é‚®ä»¶è”ç³»åŠ å…¥æˆ‘ä»¬ã€‚</p>

<p>ğŸ“§ <strong>Email:</strong> ictwangbin@gmail.com / wangbin@pjlab.org.cn</p>

<h1 id="ä¸ºä»€ä¹ˆåŠ å…¥æˆ‘ä»¬">ä¸ºä»€ä¹ˆåŠ å…¥æˆ‘ä»¬ï¼Ÿ</h1>

<p><strong>1. åšæœ‰ä»·å€¼çš„å‰æ²¿ç ”ç©¶</strong><br />
æˆ‘ä»¬çš„æ–¹å‘â€”â€”å¤šæ¨¡æ€å¤§æ¨¡å‹ã€æ™ºèƒ½æ–‡æ¡£è§£æå’Œ Data-Centric AIï¼Œæ˜¯é€šå¾€ AGI çš„å¿…ç»ä¹‹è·¯ã€‚æˆ‘ä¸æƒ³å¸¦å¤§å®¶ä¸ºäº†å‘è®ºæ–‡è€Œå‘è®ºæ–‡ï¼Œæˆ–è€…åšä½æ°´å¹³çš„é‡å¤å»ºè®¾ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åªåšä¸¤ä»¶äº‹ï¼šè¦ä¹ˆè§£å†³äº§ä¸šç•Œæœ€æ£˜æ‰‹çš„ç—›ç‚¹ï¼Œè¦ä¹ˆæŒ‘æˆ˜å­¦æœ¯ç•Œæœªè§£çš„éš¾é¢˜ã€‚<strong>è¦åšï¼Œå°±åšèƒ½è¢«åŒè¡Œè®°ä½ã€è¢«å¼€å‘è€…çœŸæ­£ä½¿ç”¨çš„å·¥ä½œã€‚</strong></p>

<p><strong>2. å……è¶³çš„èµ„æºä¸çº¯ç²¹çš„æ°›å›´</strong><br />
ç®—åŠ›æ˜¯åšå¤§æ¨¡å‹ç ”ç©¶çš„åº•æ°”ã€‚å®éªŒå®¤æ‹¥æœ‰å……è¶³çš„ GPU é›†ç¾¤ï¼Œä½ ä¸å¿…å› ä¸ºèµ„æºå—é™è€Œç¼©æ‰‹ç¼©è„šï¼Œå¯ä»¥å¤§èƒ†å»éªŒè¯é‚£äº›æ˜‚è´µçš„æƒ³æ³•ã€‚ç»„é‡Œçš„å°ä¼™ä¼´å‡æ¥è‡ªé¡¶å°–é«˜æ ¡ï¼Œå¤§å®¶å¹´é¾„ç›¸ä»¿ï¼Œç§‘ç ”æ°›å›´å¾ˆçº¯ç²¹ã€‚å¯¹äºåšå£«ç”Ÿå’Œå®ä¹ ç”Ÿï¼Œå®éªŒå®¤æä¾›ä¸é”™çš„æ´¥è´´ï¼Œè®©å¤§å®¶å¯ä»¥ä¸“æ³¨äºæŠ€æœ¯çªç ´ã€‚</p>

<p><strong>3. äº¦å¸ˆäº¦å‹ï¼Œå…¨æµç¨‹æŒ‡å¯¼</strong><br />
æˆ‘è‡ªå·±ä¹Ÿæ˜¯ä»å­¦ç”Ÿè¿‡æ¥çš„ï¼Œæ·±çŸ¥å¤§å®¶åœ¨ä¸åŒé˜¶æ®µçš„ç—›ç‚¹ï¼Œæ‰€ä»¥æˆ‘æ‹’ç»â€œæ”¾å…»â€ã€‚</p>
<ul>
  <li><strong>å®šåˆ¶åŒ–åŸ¹å…»</strong>ï¼šæˆ‘ä¸ä¼šå½“â€œç”©æ‰‹æŒæŸœâ€ã€‚ä»é€‰é¢˜ã€Coding åˆ°å†™ Paperï¼Œæˆ‘ä¼šæä¾›ä¸€å¯¹ä¸€æŒ‡å¯¼ï¼Œå¹¶æ ¹æ®ä½ çš„ç‰¹é•¿è§„åˆ’è·¯çº¿ã€‚</li>
  <li><strong>æ¸…æ™°çš„è·¯å¾„</strong>ï¼šæˆ‘ä»¬æ¯å‘¨éƒ½æœ‰å‰æ²¿ Paper Readingã€‚æˆ‘çš„ç›®æ ‡å¾ˆæ˜ç¡®ï¼šå¸¦ä½ èµ°å®Œä»ã€å¤¯å®åŸºç¡€ã€‘åˆ°ã€ç‹¬ç«‹å‘é¡¶ä¼šã€‘ï¼Œå†åˆ°ã€åšå‡ºå½±å“åŠ›å·¥ä½œã€‘çš„å…¨è¿‡ç¨‹ï¼Œæœ€ç»ˆæŠŠä½ åŸ¹å…»æˆèƒ½ç‹¬å½“ä¸€é¢çš„ç ”ç©¶è€…ã€‚</li>
  <li><strong>å¹³ç­‰çš„äº¤æµ</strong>ï¼šä½œä¸ºé’å¹´å¯¼å¸ˆï¼Œæˆ‘ä»¬ä¹‹é—´æ²¡æœ‰ä»£æ²Ÿã€‚æ— è®ºæ˜¯ç§‘ç ”å¡å£³äº†ï¼Œè¿˜æ˜¯å¯¹æœªæ¥è¿·èŒ«äº†ï¼Œéšæ—¶éƒ½å¯ä»¥æ‰¾æˆ‘èŠã€‚</li>
</ul>

<p><strong>4. æœŸå¾…ä½ çš„åŠ å…¥</strong><br />
ç›®å‰ 2026 çº§åšå£«ç”Ÿåé¢å·²æ»¡ï¼Œéå¸¸æ¬¢è¿ <strong>2027 çº§ç›´åšç”Ÿã€æ™®åšç”Ÿ</strong> æå‰è”ç³»æ¥ç»„é‡Œå®ä¹ ã€‚
åšç§‘ç ”æ˜¯ä¸€åœºé•¿è·‘ï¼Œå¸Œæœ›èƒ½æ‰¾åˆ°å¿—åŒé“åˆçš„ä½ ï¼Œ<strong>ä¸€èµ·åœ¨å¤§æ¨¡å‹æ—¶ä»£åšç‚¹ä¸ä¸€æ ·çš„äº‹æƒ…ã€‚</strong>
<em>(æ³¨ï¼šå¯¹äºå·²ç»æ¯•ä¸šçš„ä¼˜ç§€ç ”ç©¶äººå‘˜ï¼Œå¦‚æœæ¸´æœ›åœ¨å…·æœ‰å½±å“åŠ›çš„å¹³å°ä¸Šæ–½å±•æ‹³è„šï¼ŒåŒæ ·æ¬¢è¿è”ç³»åŠ å…¥ã€‚)</em></p>

<h1 id="-news">ğŸ”¥ News</h1>

<h3 id="2025">2025:</h3>
<ul>
  <li><em>2025.09</em>: Â ğŸ‰ğŸ‰  MinerU 2.5 is released! A 1.2B vision-language model for document parsing. <a href="https://arxiv.org/abs/2509.22186">[Tech Report]</a> <a href="https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B">[Hugging Face Model]</a> <a href="https://github.com/opendatalab/MinerU/">[GitHub]</a>
    <ul>
      <li>SOTA Performance: Surpasses general models (Gemini 2.5-Pro, GPT-4o, etc.) and specialized tools (MonkeyOCR, PP-StructureV3).</li>
      <li>High Efficiency: Achieves top accuracy with significantly greater speed than large-model solutions.</li>
    </ul>
  </li>
  <li><em>2025.06</em>: Â ğŸ‰ğŸ‰ OHR, LEGION and Chimera are accepted by ICCV 2025.</li>
  <li><em>2025.02</em>: Â ğŸ‰ğŸ‰ OmniDocBench and CDM are accepted by CVPR 2025.</li>
  <li><em>2025.01</em>: Â ğŸ‰ğŸ‰ GeoX and OmniCorpus are accepted by ICLR 2025.</li>
</ul>

<h3 id="2024">2024:</h3>
<ul>
  <li><em>2024.09</em>: Â ğŸ‰ğŸ‰ InternLM-XComposer2-4KHD is accepted by NeurIPS 2024.</li>
  <li><em>2024.07</em>: Â ğŸ”¥ğŸ”¥ğŸ”¥ <a href="https://github.com/opendatalab/PDF-Extract-Kit"><img src="images/pdf-extract-kit_logo.png" width="150px" style="vertical-align:bottom;" /></a> has received <strong><span style="color:red">3500+</span></strong> GitHub stars within one month.</li>
  <li><em>2024.07</em>: Â ğŸ”¥ğŸ”¥ğŸ”¥ <a href="https://github.com/opendatalab/MinerU"><img src="images/mineru-logo.png" width="90px" style="vertical-align:bottom;" /></a> has received <strong><span style="color:red">4200+</span></strong> GitHub stars and <strong><span style="color:red">ranked #1</span></strong> on the GitHub Trending list.</li>
  <li><em>2024.07</em>: Â ğŸ‰ğŸ‰ CLIP-Parrot-Bias is accepted by ECCV 2024 (<span style="color:red"><strong>Oral</strong></span>).</li>
  <li><em>2024.02</em>: Â ğŸ‰ğŸ‰ OPERA is accepted by CVPR 2024.</li>
  <li><em>2023.12</em>: Â ğŸ‰ğŸ‰ VIGC is accepted by AAAI 2024.</li>
  <li><em>2023.12</em>: Â ğŸ‰ğŸ‰ One paper is accepted by IJAEOG 2024.</li>
  <li><em>2023.08</em>: Â ğŸ‰ğŸ‰ DropQueries is accepted by TMM 2023.</li>
  <li><em>2023.08</em>: Â ğŸ‰ğŸ‰ V3Det is accepted by ICCV 2023 (<span style="color:red"><strong>Oral</strong></span>). 
<!-- - *2022.07*: &nbsp;ğŸ‰ğŸ‰ PG-MPI is accepted by ECCV2022. --></li>
</ul>

<h1 id="-project">ğŸš€ Project</h1>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">Github Repo</div><img src="images/mineru2_5.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://arxiv.org/abs/2509.22186"><strong>MinerU2.5</strong>: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing <strong>(Project Lead)</strong></a>| 
 <a href="https://huggingface.co/spaces/opendatalab/MinerU"><strong>Demo(Hugging Face)</strong></a> | 
 <a href="https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B"><strong>Models(Hugging Face)</strong></a> | <a href="https://modelscope.cn/models/OpenDataLab/MinerU2.5-2509-1.2B"><strong>Models(ModelScope)</strong></a> | <a href="https://github.com/opendatalab/MinerU"><strong>Github</strong> <img src="https://img.shields.io/github/stars/opendatalab/MinerU" alt="" /></a></p>
  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">Github Repo</div><img src="images/pdf-extract-kit-pipeline.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><strong>PDF-Extract-Kit</strong>: A Comprehensive Toolkit for High-Quality PDF Content Extraction <strong>(Project Lead)</strong></p>

    <p><a href="https://huggingface.co/wanderkid/PDF-Extract-Kit"><strong>Models(Hugging Face)</strong></a> | <a href="https://www.modelscope.cn/models/wanderkid/PDF-Extract-Kit"><strong>Models(ModelScope)</strong></a> | <a href="https://github.com/opendatalab/PDF-Extract-Kit"><strong>Github</strong> <img src="https://img.shields.io/github/stars/opendatalab/PDF-Extract-Kit" alt="" /></a></p>
  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">Github Repo</div><img src="images/mineru-pipeline.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://arxiv.org/abs/2409.18839"><strong>MinerU</strong>: An Open-Source Solution for Precise Document Content Extraction <strong>(Project Lead)</strong></a>
 <a href="https://trendshift.io/repositories/11174" target="_blank"><img src="https://trendshift.io/api/badge/repositories/11174" alt="opendatalab%2FMinerU | Trendshift" style="width: 200px; height: 55px;" /></a> | <a href="https://github.com/opendatalab/MinerU"><strong>Github</strong> <img src="https://img.shields.io/github/stars/opendatalab/MinerU" alt="" /></a></p>
  </div>
</div>

<h1 id="-publications">ğŸ“ Publications</h1>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">ECCV 2024</div><img src="images/eccv2024_clip-parrot-bias.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://arxiv.org/abs/2312.14232">Parrot Captions Teach CLIP to Spot Text</a></p>

    <p>Yiqi Lin<sup>*</sup>, Conghui He<sup>*</sup>, Alex Jinpeng Wang<sup>*</sup>, <strong>Bin Wang</strong><sup>*</sup>, Weijia Li, Mike Zheng Shou</p>

    <p>ECCV 2024 <span style="color:red"><strong>Oral</strong></span>, | <a href="https://linyq17.github.io/CLIP-Parrot-Bias/"><strong>Project</strong></a> | <a href="https://github.com/opendatalab/CLIP-Parrot-Bias"><strong>Github</strong> <img src="https://img.shields.io/github/stars/opendatalab/CLIP-Parrot-Bias" alt="" /></a></p>
  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">AAAI 2024</div><img src="images/AAAI2024_VIGC.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://arxiv.org/abs/2308.12714">VIGC: Visual Instruction Generation and Correction</a></p>

    <p><strong>Bin Wang</strong>, Fan Wu, Xiao Han, Jiahui Peng, Huaping Zhong, Pan Zhang, Xiaoyi Dong, Weijia Li, Wei Li, Jiaqi Wang, Conghui He</p>

    <p>AAAI 2024, | <a href="https://opendatalab.github.io/VIGC/"><strong>Project</strong></a> | <a href="https://github.com/opendatalab/VIGC"><strong>Github</strong> <img src="https://img.shields.io/github/stars/opendatalab/VIGC" alt="" /></a></p>
  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">IJAEOG 2024</div><img src="images/IJAEOG.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://www.sciencedirect.com/science/article/pii/S1569843223004338">Exploring the user guidance for more accurate building segmentation from high-resolution remote sensing images</a></p>

    <p>Dinghao Yang<sup>*</sup>, <strong>Bin Wang</strong><sup>*</sup>, Weijia Li, Conghui He</p>

    <p>IJAEOG 2024,  | <a href="https://github.com/StephenDHYang/UGBS-pytorch"><strong>Github</strong> <img src="https://img.shields.io/github/stars/StephenDHYang/UGBS-pytorch" alt="" /></a></p>
  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">TMM 2023</div><img src="images/DropQuery.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=zh-CN&amp;user=WljXYoYAAAAJ&amp;sortby=pubdate&amp;citation_for_view=WljXYoYAAAAJ:ufrVoPGSRksC">DropQueries: A Simple Way to Discover Comprehensive Segment Representations</a></p>

    <p>Haojie Ding, <strong>Bin Wang</strong>, Guoliang Kang, Weijia Li, Conghui He, Yao Zhao, and Yunchao Wei</p>

    <p>TMM 2023</p>
  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">ICCV 2023</div><img src="images/V3Det.jpg" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://arxiv.org/abs/2304.03752">V3Det: Vast Vocabulary Visual Detection Dataset</a></p>

    <p>Jiaqi Wang, Pan Zhang, Tao Chu, Yuhang Cao, Yujie Zhou, Tong Wu, <strong>Bin Wang</strong>, Conghui He, and Dahua Lin</p>

    <p>ICCV 2023 <span style="color:red"><strong>Oral</strong></span>, | <a href="https://v3det.openxlab.org.cn/"><strong>Project</strong></a> | <a href="https://github.com/V3Det/V3Det"><strong>Github</strong> <img src="https://img.shields.io/github/stars/V3Det/V3Det?style=social" alt="" /></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">IJCAI 2019</div><img src="images/IJCAI2019_BPG.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://opus.lib.uts.edu.au/bitstream/10453/141475/2/0508.pdf">Boundary perception guidance: A scribble-supervised semantic segmentation approach</a></p>

    <p><strong>Bin Wang</strong>, Guojun Qi, Sheng Tang, Tianzhu Zhang, Yunchao Wei, Linghui Li, and Yongdong Zhang</p>

    <p>IJCAI 2019</p>
  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">MICCAI 2019</div><img src="images/MICCAI2019.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=zh-CN&amp;user=WljXYoYAAAAJ&amp;citation_for_view=WljXYoYAAAAJ:u5HHmVD_uO8C">Spatiotemporal Breast Mass Detection Network(MD-Net) in 4D DCE-MRI Images</a></p>

    <p>Lixi Deng, Sheng Tang, Huazhu Fu, <strong>Bin Wang</strong>, and Yongdong Zhang</p>

    <p>MICCAI 2019</p>
  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">MICCAI 2018</div><img src="images/MICCAI2018_Nodule.png" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=zh-CN&amp;user=WljXYoYAAAAJ&amp;citation_for_view=WljXYoYAAAAJ:2osOgNQ5qMEC">Automated pulmonary nodule detection: High sensitivity with few candidates</a></p>

    <p><strong>Bin Wang</strong>, Guojun Qi, Sheng Tang, Liheng Zhang, Lixi Deng, and Yongdong Zhang</p>

    <p>MICCAI 2018</p>
  </div>
</div>

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2021</div><img src='images/cocosnet_v2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation](https://arxiv.org/pdf/2012.02047.pdf)

Xingran Zhou, Bo Zhang, Ting Zhang, **Pan Zhang**, Jianmin Bao, Dong Chen, Zhongfei Zhang, Fang Wen

CVPR 2021 <span style="color:red">**Oral**</span>, [<span style="color:red">**Best Paper Candidate**</span>](https://cvpr2021.thecvf.com/node/290) \| [**Github** ![](https://img.shields.io/github/stars/microsoft/CoCosNet-v2?style=social)](https://github.com/microsoft/CoCosNet-v2) \| [**Slides**](https://www.dropbox.com/s/g7dezxm2mhw6gqo/CoCosNet%20slides.pptx?dl=0)

</div>
</div> -->

<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

<h1 id="-honors-and-awards">ğŸ– Honors and Awards</h1>
<ul>
  <li><em>2020.06</em>, Zhu Li Yuehua Outstanding Ph.D. student Scholarship, Chinese Academy of Sciences (CAS).</li>
  <li><em>2016.09</em>, Won 3rd place in the ILSVRC 2016 VID task (Object Detection from Video).</li>
</ul>

<!-- - *2017.06*, Honor Ranking of Talent Program in Information Science and Technology (For top 5% students by USTC). 
- *2015.06*, National Scholarship (The highest scholarship awarded by the Ministry of Education, China).
- *2014.06*, National Scholarship (The highest scholarship awarded by the Ministry of Education, China). -->

<h1 id="-work-experience">ğŸ¢ Work Experience</h1>
<ul>
  <li><em>2020.07 - 2022.08</em>, Researcher, SenseTime, Shenzhen, China.</li>
</ul>

<h1 id="-education">ğŸ“– Education</h1>
<ul>
  <li><em>2015.09 - 2020.06</em>, Ph.D., University of Chinese Academy of Sciences, Beijing, China.</li>
  <li><em>2013.09 - 2015.06</em>, M.S., Beijing Jiaotong University, Beijing, China.</li>
</ul>

          </section>
        </div>
      </article>
    </div>

    <script src="assets/js/main.min.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', "");
</script>


<script>
    $(document).ready(function () {
        
        var gsDataBaseUrl = 'https://cdn.jsdelivr.net/gh/wangbinDL/wangbinDL.github.io@'
        
        $.getJSON(gsDataBaseUrl + "google-scholar-stats/gs_data.json", function (data) {
            var totalCitation = data['citedby']
            document.getElementById('total_cit').innerHTML = totalCitation;
            var citationEles = document.getElementsByClassName('show_paper_citations')
            Array.prototype.forEach.call(citationEles, element => {
                var paperId = element.getAttribute('data')
                var numCitations = data['publications'][paperId]['num_citations']
                element.innerHTML = '| Citations: ' + numCitations;
            });
        });
    })
</script>


  </body>
</html>
